{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada121b1",
   "metadata": {},
   "source": [
    "## Starting of Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357ef05a",
   "metadata": {},
   "source": [
    "### Generating Fake Bio data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4bcd27",
   "metadata": {},
   "source": [
    "#### The first thing we do is import all the necessary libraries for us to run our web-scraper. We will be explaining the exceptional library packages for BeautifulSoup to run properly such as:\n",
    "\n",
    "##### ♦requests allows us to access the webpage that we need to scrape.\n",
    "##### ♦time will be needed in order to wait between webpage refreshes.\n",
    "##### ♦tqdm is only needed as a loading bar for our sake.\n",
    "##### ♦bs4 is needed in order to use BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.31.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2023.11.17)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.66.1)\n",
      "Requirement already satisfied: bs4 in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\aksha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4f59026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import re #regex\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm \n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91dd7670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomizing the refresh rate\n",
    "seq = [i/10 for i in range(8, 18)]\n",
    "\n",
    "# Creating a list of bios\n",
    "biolist = []\n",
    "\n",
    "# Gathering bios by looping and refreshing the web page\n",
    "for _ in range(20):  # Removed tqdm(range(1000))\n",
    "    \n",
    "    # Refreshing the page\n",
    "    page = requests.get(\"https://www.fakepersongenerator.com/user-biography-generator\")\n",
    "    soup = bs(page.content)\n",
    "    \n",
    "    try:\n",
    "        # Getting the bios\n",
    "        bios = soup.find('div', class_='row no-margin for-sign').find_all('p')\n",
    "\n",
    "        # Adding to a list of the bios\n",
    "        biolist.extend([re.findall('\"([^\"]*)\"', i.text) for i in bios])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Sleeping \n",
    "    time.sleep(random.choice(seq))\n",
    "    \n",
    "# Creating a DF from the bio list\n",
    "bio_df = pd.DataFrame(biolist, columns=['Bios'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5427208d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bios</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gamer. Twitter ninja. Travel scholar. Bacon gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Introvert. Unapologetic gamer. General coffee ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food nerd. Coffee buff. Tv aficionado. Amateur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Incurable internet maven. Reader. Introvert. U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Incurable explorer. Subtly charming twitter gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Pop culture buff. Hipster-friendly communicato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Tv enthusiast. Analyst. Friendly web lover. Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Lifelong web buff. General coffee practitioner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Professional writer. Incurable explorer. Twitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Creator. Certified bacon guru. Introvert. Hard...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Bios\n",
       "0    Gamer. Twitter ninja. Travel scholar. Bacon gu...\n",
       "1    Introvert. Unapologetic gamer. General coffee ...\n",
       "2    Food nerd. Coffee buff. Tv aficionado. Amateur...\n",
       "3    Incurable internet maven. Reader. Introvert. U...\n",
       "4    Incurable explorer. Subtly charming twitter gu...\n",
       "..                                                 ...\n",
       "280  Pop culture buff. Hipster-friendly communicato...\n",
       "281  Tv enthusiast. Analyst. Friendly web lover. Pr...\n",
       "282  Lifelong web buff. General coffee practitioner...\n",
       "283  Professional writer. Incurable explorer. Twitt...\n",
       "284  Creator. Certified bacon guru. Introvert. Hard...\n",
       "\n",
       "[285 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a34b12c",
   "metadata": {},
   "source": [
    "#### Now, we will generate interests with a range from 0-9 depicting the interest level. The numbers represent the specific interest in the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "241cdae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bios</th>\n",
       "      <th>Movies</th>\n",
       "      <th>TV</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Music</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Travelling</th>\n",
       "      <th>Foodie</th>\n",
       "      <th>Books</th>\n",
       "      <th>Politics</th>\n",
       "      <th>Finance</th>\n",
       "      <th>Coding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gamer. Twitter ninja. Travel scholar. Bacon gu...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Introvert. Unapologetic gamer. General coffee ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food nerd. Coffee buff. Tv aficionado. Amateur...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Incurable internet maven. Reader. Introvert. U...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Incurable explorer. Subtly charming twitter gu...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Pop culture buff. Hipster-friendly communicato...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Tv enthusiast. Analyst. Friendly web lover. Pr...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Lifelong web buff. General coffee practitioner...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Professional writer. Incurable explorer. Twitt...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Creator. Certified bacon guru. Introvert. Hard...</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Bios  Movies  TV  Religion  \\\n",
       "0    Gamer. Twitter ninja. Travel scholar. Bacon gu...       4   6         9   \n",
       "1    Introvert. Unapologetic gamer. General coffee ...       3   1         2   \n",
       "2    Food nerd. Coffee buff. Tv aficionado. Amateur...       0   7         7   \n",
       "3    Incurable internet maven. Reader. Introvert. U...       5   4         3   \n",
       "4    Incurable explorer. Subtly charming twitter gu...       4   3         7   \n",
       "..                                                 ...     ...  ..       ...   \n",
       "280  Pop culture buff. Hipster-friendly communicato...       3   2         3   \n",
       "281  Tv enthusiast. Analyst. Friendly web lover. Pr...       3   5         9   \n",
       "282  Lifelong web buff. General coffee practitioner...       2   3         0   \n",
       "283  Professional writer. Incurable explorer. Twitt...       2   0         4   \n",
       "284  Creator. Certified bacon guru. Introvert. Hard...       9   6         0   \n",
       "\n",
       "     Music  Sports  Travelling  Foodie  Books  Politics  Finance  Coding  \n",
       "0        5       4           0       0      3         8        9       2  \n",
       "1        6       7           9       4      3         5        1       5  \n",
       "2        8       3           2       4      8         2        9       1  \n",
       "3        0       0           8       9      1         5        8       4  \n",
       "4        6       3           2       1      0         7        7       7  \n",
       "..     ...     ...         ...     ...    ...       ...      ...     ...  \n",
       "280      8       1           6       7      8         0        6       8  \n",
       "281      8       8           8       7      9         1        6       2  \n",
       "282      6       3           8       1      9         0        8       4  \n",
       "283      9       5           2       1      9         9        3       8  \n",
       "284      5       4           6       2      1         8        8       5  \n",
       "\n",
       "[285 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using random library of python, we will generate a range from 0 to 9.\n",
    "\n",
    "# We have set a list of common interests which will be asked by th user on the time of profile creation\n",
    "\n",
    "interests_list = [\n",
    "    'Movies',\n",
    "    'TV',\n",
    "    'Religion',\n",
    "    'Music',\n",
    "    'Sports',\n",
    "    'Travelling',\n",
    "    'Foodie',\n",
    "    'Books',\n",
    "    'Politics',\n",
    "    'Finance',\n",
    "    'Coding',\n",
    "]\n",
    "\n",
    "# Now creating a datafame of these inputs\n",
    "interest_df = pd.DataFrame(columns = interests_list)\n",
    "\n",
    "# Filling in Data\n",
    "for i in interest_df.columns:\n",
    "    \n",
    "    # Range of numbers to represent different labels in each category\n",
    "    interest_df[i] = np.random.randint(0,10, bio_df.shape[0])\n",
    "    \n",
    "    # Logic: The numbers represent a specific choice within the categories\n",
    "    # So the number 1 preferred artist/song/album under the Music, your one favorite movie, etc.\n",
    "    \n",
    "# Joining the two dataframes\n",
    "final_df = bio_df.join(interest_df)\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af230a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a pickle file of the final dataframe \n",
    "# Exporting the complete DF\n",
    "with open(\"profile_data.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(final_df, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
